<!DOCTYPE html>
<html>

<head>
  <title>ProgL Final Presentation</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <link rel="stylesheet" href="fonts/quadon/quadon.css">
  <link rel="stylesheet" href="fonts/gentona/gentona.css">
  <link rel="stylesheet" href="slides_style_i.css">
  <script type="text/javascript" src="assets/plotly/plotly-latest.min.js"></script>
</head>

<body>
  <textarea id="source">




### Practical Progressive Learning 

<p style="font-size:0.875em">
Ronak Mehta <br>
Microsoft Research Team Essex <br>
Summer Internship 2020 <br>
August 18, 2020
</p>

.center[![:scale 45%](images/microsoft.gif) ![:scale 35%](images/jhu_white.png)]
<!-- .center[![:scale 20%](images/jhu_white.png)] -->

<p style="font-style: italic;">Slides adapted from "Transmedia progressive learning" by Joshua Vogelstein.</p>

---

### What is Progressive Learning?

--

- Given a .ye[set of tasks] (image classification, sentiment analysis, hypothesis testing)...

--

- and some .ye[side information] (pre-trained models (ResNet, BERT), expert/oracle advice, inductive bias)... 

--

- .ye[perform better on each task] by virtue of the other tasks and information.

---

#### Make ML mirror Neurobiology

--

- Omnidirectional transfer

- Sequential updates

- Selective plasticity / Robustness

- Quick adaptation to unseen tasks

---

### Previous Approach

Let $x$ be some input, $t$ is a task label, $y$ be a label, and $h$ be predictor that makes $h(x, t)$ close to $y$. 

--

.center[![:scale 80%](images/Decompose.png)]

---

### Key Idea 

- Transformers from other tasks (or side information) can be used as additional representations.
- This is .ye[ensembling representations].
- Can be done in .ye[federated] way: we don't need all the data at once or in one place.

--

.center[![:scale 80%](images/Ensemble.png)]

---

### My Goals

- A mathematically formal statement of PL, theoretical analysis of ensembling representations.

- Extentions of ensembling representations for practical scenarios.

---

#### Practical PL: Task Unaware + Robust


- We currently learn a .ye[task aware] classifier $h(x, t)$
- Extension 1: .ye[task unaware] $h(x)$
  - Within environment ($t$ associated to $x$ is seen before)
  - Out-of-environment / Zero-shot ($t$ associated to $x$ is new.)
- Extension 2: .ye[robust] $h(x, t)$ that uses the other transformers only if it helps.

---

#### Measure of Performance

The Transfer Efficiency (TE) is defined as:

$$ TE^t = \frac{\mathbb{E}\left[\text{error using only task } t \text { data}\right]}{\mathbb{E}\left[\text{error of using all data and information}\right]} $$

--

.ye[$TE$ measures NOT how valuable side information is, but how much the algorithm leverages it.]

---

#### Experiment 1: CIFAR 10x10

- Image classification dataset with 10 tasks, each being 10 class classification.
  - Task 1: Classify images of bears, dolphins, motorcycles, ...
  - Task 2: Classify images of palm trees, chairs, sweet peppers, ...

--

- Task aware test set up: give $h$ an image $x$ and a task $t$ (1-10), and guess object $y$.
- Task unaware set up: just give $h$ an image $x$.
- Upper bound is performance on "joint learning" classifier that gets all task data (100 classes) at once.  

---

#### Experiment 1: CIFAR 10x10 (Task Unaware)

.center[![:scale 80%](images/cifar100_task_obl_fig.png)]

---

#### Experiment 1: CIFAR 10x10 (Robust)

- Test four methods for robust learning that selectively use the other transformers.
.center[![:scale 100%](images/robust_fig.png)]


---

### Experiment 2: Reviews

- 3 datasets (tasks) each with text reviews of some item, and a sentiment (+ or -).
  - Yelp (Task 1): Classify sentiment of restuarants reviews.
  - IMDB (Task 2): Classify sentiment of movie reviews.
  - Amazon (Task 3): Classify sentiment of product reviews.

---

#### Experiment 2: Reviews (Task Unaware)

- Classify Amazon reviews having only trained on Yelp and IMDB reviews.
.center[![:scale 80%](images/review_zero_shot.png)]

---

#### Experiment 3: Icon Recognition
- 105 datasets each with images of UI icons and labels (pause, play, save, email, etc).
  - 70 tasks: Random subset of 7 icons.

---

#### Experiment 3: Icon Recog. (Task Unaware)

.center[![:scale 80%](images/icon_task_obl_fig.png)]
Weiwei Yang

---

## Takeaways

--

1. PL is general enough to apply to a wide range of domains.

--

2. PL is flexible enough to exhibit selective plasticity / robustness.

--

3. PL can exhibit near "optimal" performance in task unaware settings.

--

4. If tasks are similar enough, task unaware PL can exhibit zero-shot learning.

---

### Limitations / Room for Future Work

--

- The extent of zero-shot learnability.

- Weighted average of transformers instead of selecting them.

- Simulations / theory for task unaware learning.

- An end-to-end system that relies on this PL.

---

<!-- #### Where We Are

1. Theory
  - .ye[Formal set up PL (transfer, multitask)]
  - .ye[Theorems regarding transferability and robustness.]
2. Methods
  - Proposed PL framework by ensembling representations.
  - .ye[proglearn software package ([code](https://github.com/neurodata/progressive-learning))]
  - .ye[Explored task unaware, robust transfer, and regression methods.]
3. Proof-of-Concept Applications.
  - Vision. (.ye[CIFAR 10x10], UI Icon Recognition)
  - Language. (Language Identification, .ye[Item Review Sentiment Analysis])
  - Power Systems. (Load forecasting) -->

---
 

### Acknowledgements

#### MSR
- Weiwei Yang
- Chris White
- Team Essex
- Fellow Interns: Ben, Hayden, Jialong, Rachel, Yize

### JHU
- Joshua T. Vogelstein
- Carey Priebe
- PL Team: Jayanta Dey, Will LeVine, Ali Geiza

---


.center[Questions/Comments/Feedback?]

---

.center[THANK YOU!]

---

.center[Appendix]

---

#### Theory of the Task Learnable

- What is a task?

- What is the mathematical set up of PL (transfer, multitask)?

- How do we measure the extent of transfer?

- Formally, is being transferred between tasks (representations of data)?

- Theorems: Ensembling representations is provably successful for PL. 

---

### Task Similarity Example

.center[![:scale 100%](images/partition_example.png)]

---

### Robustness Approach

- Standard PL algorithm uses all the transformers available.
- .ye[One-vs-All]: Decide to use all of the additional transformers or none, based on training/validation accuracy.
- .ye[Sample]: Sample $c$ combinations of additional transformers, and choose the best combination based on training/validation accuracy.

---

### Task Aware Approach

- From data $(X_1, Y_1, T_1), ..., (X_n, Y_n, T_n)$, estimate $p(y \mid x, t)$ for each task by sharing transformers.
- $h(x, t)$ returns $y$ that maximizes $p(y \mid x, t)$.

---

### Task Unaware Approach 1

- From data $(X_1, Y_1, T_1), ..., (X_n, Y_n, T_n)$, estimate $p(y \mid x, t)$ for each task by sharing transformers.
- .ye[From data $(X_1, T_1), ..., (X_n, T_n)$, estimate $p(t \mid x)$].
- $h(x)$ returns $y$ that maximizes <br>
$p(y | x) = \sum\_t p(y, t \mid x) = \sum\_t p(y \mid x, t) \cdot $ .ye[$p(t \mid x)$]

---

### Task Unaware Approach 2

- Add random data to each task with the class label .ye["-1"], meaning .ye["none-of-the-above"].
- From data $(X_1, Y_1, T_1), ..., (X_n, Y_n, T_n)$, estimate $p(y \mid x, t)$ for each task by sharing transformers.
- $h(x)$ first classifies $x$ according to $p(y \mid x, t)$ for all tasks $t$.
- Among the task clasisfiers that did not yield "none-of-the-above", return $(y, t)$ that maximizes $p(y \mid x, t)$ over both $y$ and $t$.

---

### Language Task 2

.small[
1. What is application domain
  - natural language processing
2. What are the distributions from which tasks are sampled?
  - Many words from each Bing dominant type
3. What is known by agent before deployment? What gets learned?
  1. Only knowing setting 
  2. pretrained on other data 
  3. Word embeddings from existing models
4. What must be selectively remembered across tasks?
  1. transformers (eg, hidden layers) from other types  
5. How does scenario present signal and noise 
  1. many samples per class define signal per dominant type 
6. What aspects are unique to lifelong learning 
  1. sequential tasks 
7. Independent and dependent variables?
  1. Independent: # types, # terms/type 
  2. Dependent variables: forward and backward transfer efficiency
]

 


</textarea>
  <!-- <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js"></script> -->
  <!-- <script src="remark-latest.min.js"></script> -->
  <script src="remark-latest.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
  <script type="text/javascript">

    var options = {};
    var renderMath = function () {
      renderMathInElement(document.body);
      // or if you want to use $...$ for math,
      renderMathInElement(document.body, {
        delimiters: [ // mind the order of delimiters(!?)
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\[", right: "\\]", display: true },
          { left: "\\(", right: "\\)", display: false },
        ]
      });
    }

    remark.macros.scale = function (percentage) {
      var url = this;
      return '<img src="' + url + '" style="width: ' + percentage + '" />';
    };

    // var slideshow = remark.create({
    // Set the slideshow display ratio
    // Default: '4:3'
    // Alternatives: '16:9', ...
    // {
    // ratio: '16:9',
    // });

    var slideshow = remark.create(options, renderMath);


  </script>
</body>

</html>